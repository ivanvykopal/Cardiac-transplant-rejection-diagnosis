{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650d1037-d358-4ba2-acc0-eb17b80b4e4d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "from Utils.Preprocessing.MaskCreator import MaskCreator\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ecb3c2-03da-4e4f-aa0c-a2860e7ee6de",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mask_creator = MaskCreator('files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af014a6f-b9c5-40db-8733-61f289fb8b76",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_files(patch_size):\n",
    "    #with open(f'./data/images_{patch_size}.json') as json_file:\n",
    "    with open(f'D:/Master Thesis/Code/Segmentation/data5/images_{patch_size}_{patch_size // 2}.json') as json_file:\n",
    "        train_valid_json = json.load(json_file)\n",
    "\n",
    "    files = []\n",
    "    for image in train_valid_json['images']:\n",
    "        for idx, fragment in enumerate(image['fragments']):\n",
    "            for patch in fragment['patches']:\n",
    "                files.append({\n",
    "                    \"patch\": patch,\n",
    "                    \"name\": image['name'],\n",
    "                    \"height\": image['height'],\n",
    "                    \"width\": image['width'],\n",
    "                    \"fragment\": {\n",
    "                        \"idx\": idx,\n",
    "                        \"x\": fragment['x'],\n",
    "                        \"y\": fragment['y'],\n",
    "                        \"width\": fragment['width'],\n",
    "                        \"height\": fragment['height']\n",
    "                    }\n",
    "                })\n",
    "                \n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269ff41a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "files = get_files(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cf8a57",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1add32-b92a-4989-8c18-e8977d84f7fe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_split(mask_creator, patch_size=256, fat_predicted=False, remove_infla=True, remove_endocariums=False):\n",
    "    df_label = pd.DataFrame()\n",
    "    files = get_files(patch_size)\n",
    "    \n",
    "    annotation_classes = [\n",
    "        \"endocariums\"\n",
    "      ]\n",
    "    \n",
    "    for file in tqdm(files, total=len(files)):\n",
    "        mask_patch = mask_creator.create_mask_from_DB(\n",
    "                image={\n",
    "                    \"name\": file['name'],\n",
    "                    \"height\": file['height'],\n",
    "                    \"width\": file['width']\n",
    "                },\n",
    "                patch=(file['patch'][1], file['patch'][0], patch_size),\n",
    "                fragment=(file['fragment']['x'], file['fragment']['y'], file['fragment']['width'], file['fragment']['height']),\n",
    "                annotation_classes=annotation_classes\n",
    "            )\n",
    "\n",
    "        labels = {\n",
    "            'file_name': file['name'],\n",
    "            'patch_x': file['patch'][1],\n",
    "            'patch_y': file['patch'][0],\n",
    "            'height': file['height'],\n",
    "            'width': file['width'],\n",
    "            'fragment_idx': file['fragment']['idx'],\n",
    "            'fragment_x': file['fragment']['x'],\n",
    "            'fragment_y': file['fragment']['y'],\n",
    "            'fragment_height': file['fragment']['height'],\n",
    "            'fragment_width': file['fragment']['width'],\n",
    "            'type': 'normal'\n",
    "        }\n",
    "        \n",
    "        for idx_c, c in enumerate(annotation_classes):\n",
    "            unique, count = np.unique(mask_patch[:, :, idx_c], return_counts=True)\n",
    "            if 1 in unique:\n",
    "                if len(unique) == 2:\n",
    "                    labels[c] = count[1]\n",
    "                    labels['background'] = count[0]\n",
    "                else: \n",
    "                    labels[c] = count[0]\n",
    "                    labels['background'] = 0\n",
    "            else:\n",
    "                labels[c] = 0\n",
    "                labels['background'] = count[0]\n",
    "\n",
    "        df_label = pd.concat([\n",
    "            df_label,\n",
    "            pd.DataFrame([labels])\n",
    "        ])\n",
    "    \n",
    "    final_df = df_label\n",
    "    df = df_label\n",
    "    df = df.sample(frac=1)\n",
    "    if patch_size == 256:\n",
    "        valid_df = df[:6000]\n",
    "        df = df[6000:]\n",
    "    else:\n",
    "        valid_df = df[:4500]\n",
    "        df = df[4500:]\n",
    "        \n",
    "    df_label = df\n",
    "\n",
    "    endocariums_df_vertical = df.copy()\n",
    "    endocariums_df_horizontal = df.copy()\n",
    "    endocariums_df_ver_hor = df.copy()\n",
    "\n",
    "    endocariums_df_vertical['type'] = 'vertical_flip'\n",
    "    endocariums_df_horizontal['type'] = 'horizontal_flip'\n",
    "\n",
    "    # Add augmentation for blood vessels\n",
    "    df = pd.concat([\n",
    "        df,\n",
    "        endocariums_df_vertical,\n",
    "        endocariums_df_horizontal,\n",
    "        endocariums_df_ver_hor\n",
    "    ])\n",
    "\n",
    "    train_filenames = df\n",
    "    valid_filenames = valid_df\n",
    "\n",
    "    return final_df, train_filenames, valid_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163ddc87-bef7-4c4d-b876-57f6e625207c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_jsons(patch_size, step, train_filenames, valid_filenames, test_filenames):\n",
    "    datasets = [train_filenames, valid_filenames, test_filenames]\n",
    "    data_types = ['train', 'valid', 'test']\n",
    "    final_json = {\n",
    "        \"train\" : [],\n",
    "        \"valid\": [],\n",
    "        \"test\": []\n",
    "    }\n",
    "    \n",
    "    for data_type, dataset in zip(data_types, datasets):\n",
    "        for index, row in dataset.iterrows():\n",
    "            if row['type'] == 'normal':\n",
    "                aug = {'type': 'normal'}\n",
    "            elif row['type'] in ['horizontal_flip', 'horizontalflip']:\n",
    "                aug = {\"type\": \"flip\", \"mode\": \"horizontal\"}\n",
    "            elif row['type'] == 'vertical_flip':   \n",
    "                aug = {\"type\": \"flip\", \"mode\": \"vertical\"}\n",
    "            elif row['type'] == 'horizontal_vertical_flip':\n",
    "                aug = {'type': 'flip', 'mode': 'horizontal_vertical'}\n",
    "\n",
    "            final_json[data_type].append({\n",
    "                'name': row['file_name'],\n",
    "                'patch': [row['patch_y'], row['patch_x']],\n",
    "                'height': row['height'],\n",
    "                'width': row['width'],\n",
    "                'fragment': {\n",
    "                    'idx': row['fragment_idx'],\n",
    "                    'x': row['fragment_x'],\n",
    "                    'y': row['fragment_y'],\n",
    "                    'width': row['fragment_width'],\n",
    "                    'height': row['fragment_height']\n",
    "                },\n",
    "                'augmentation': aug\n",
    "            })\n",
    "            \n",
    "    json_string = json.dumps(final_json)\n",
    "    with open(f\"data/srel/images_{patch_size}-{step}-splitted2.json\", 'w') as outfile:\n",
    "        outfile.write(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20389c4e-c602-4e10-b490-e2abffee81cd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df, train_filenames, valid_filenames = create_split(mask_creator=mask_creator, patch_size=512, fat_predicted=False, remove_infla=False, remove_endocariums=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88b10d1-b5ca-4b2e-85c7-790bbda3dfd6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87a4336-815b-468b-9c7f-46eb315b3d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filenames.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d76b72-7990-4ab6-8ff3-f2503f8e4bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_filenames.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d881ad-21ac-4563-a9fb-b14d5c97a846",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_filenames.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b1d956-8787-457b-a06f-b5c24cf81c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_filenames.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc87576-db21-42cd-91ff-178f44b3c4d2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "endocariums_df = df[\n",
    "    (((df[['blood_vessels', 'endocariums', 'fatty_tissues', 'inflammations']] == 0).sum(axis=1) == 3) & (df['endocariums'] != 0) & (df['type'] == 'normal'))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ea7c55-31ed-4235-b836-be84068c7fa7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "endocariums_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd09fe4-2ff3-4a54-95b4-014b3e32e2f2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "endocariums_df = endocariums_df.sample(frac=1)[:500]\n",
    "endocariums_df['type'] = 'horizontal_flip'\n",
    "\n",
    "test_df = pd.concat([\n",
    "    df,\n",
    "    endocariums_df\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a02e034-6ac2-445a-b4e3-b5fdc3eceafd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0848dd0e-564a-4116-9dae-689172ef67ed",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01a169c-d0ad-4907-b402-874a0e0346ab",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3aecaf-95c9-46f4-8338-2f75d00c81a5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "infla_df = test_df[\n",
    "    (((test_df[['blood_vessels', 'endocariums', 'fatty_tissues', 'inflammations']] == 0).sum(axis=1) == 3) & (test_df['inflammations'] != 0))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84028c7c-baba-4794-a3e1-1d9dd364b6dc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "infla_df = infla_df.sample(frac=1)[:500]\n",
    "test_df = pd.merge(test_df, infla_df, indicator=True, how='outer').query('_merge==\"left_only\"').drop('_merge', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565776e4-0b25-4c41-8e3a-6ea326c44d7b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c03b63-07ee-4ee7-9b5e-95bd9727ad75",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c56329-b53e-4705-a408-9b50954a975c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_filenames = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92b142e-6aeb-4aa5-8bc1-ed273efa4991",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_filenames.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e355b71c-c4f5-438b-a67b-ba40871b8274",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_filenames['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b47daba-1e1e-4cf6-a19f-5e9f6e1fc691",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "create_jsons(512, 256, train_filenames, valid_filenames, pd.DataFrame())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
