{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f081123-7c33-4160-b59d-ab40b01fa81b",
   "metadata": {},
   "source": [
    "# Trénovanie U-Net++ modelu\n",
    "\n",
    "**Autor: Bc. Ivan Vykopal**\n",
    "\n",
    "Notebook určený pre tréning U-Net++ modelu pre segmentáciu jadier v Lizard datasete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "864732b6-1667-4fbd-9f60-31b3b3d24d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, BatchNormalization\n",
    "from tensorflow.keras.layers import MaxPooling2D, ReLU, LeakyReLU, Activation, RandomRotation, RandomFlip, RandomZoom, RandomContrast\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Add\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.image import resize\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "import tensorflow.keras.backend as K\n",
    "import cv2 as cv\n",
    "import json\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcce864-73c5-4b13-ab02-9784ff668832",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8320e4d5-398e-4aeb-835b-e27f11a96968",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(project=\"DP U-Net++ Lizard\", entity=\"ivanvykopal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973ba6f3-02ef-4106-a62b-c53b3ab15fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'IMAGE_SIZE': 512,\n",
    "    'CHANNELS': 3,\n",
    "    'BATCH_SIZE': 4,\n",
    "    'EPOCHS': 100,\n",
    "    'PADDING': 'same',\n",
    "    'DTYPE': 'float32',\n",
    "    'FILTERS': 32,\n",
    "    'INITIALIZER': 'he_normal',\n",
    "    'KERNEL_SIZE': (3, 3),\n",
    "    'LEARNING_RATE': 0.001,\n",
    "    'DROPOUT': 0.5,\n",
    "    'THRESHOLD': 0.5,\n",
    "    'AUGMENTATIONS': [],\n",
    "    'LOSS': diceCoefLoss,\n",
    "    'METRICS': ['Accuracy', 'Precision', 'Recall', tf.keras.metrics.MeanIoU(num_classes=2), diceCoef]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d17020-f58e-4fd6-ae16-1eb5914dbff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.config.update(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06065f0-037d-4497-821a-896721a1dce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NestedUnet():\n",
    "    def __init__(self):\n",
    "        super()\n",
    "     \n",
    "    def _conv_block(self, x, n_filters, n_convs, residual=False):\n",
    "        out = tf.identity(x)\n",
    "        for i in range(n_convs):\n",
    "            out = Conv2D(n_filters, kernel_size=config['KERNEL_SIZE'], padding=config['PADDING'], kernel_initializer=config['INITIALIZER'])(out)\n",
    "            out = BatchNormalization()(out)\n",
    "            out = Activation('relu')(out)\n",
    "            \n",
    "        if residual:\n",
    "            shortcut = Conv2D(n_filters, kernel_size=config['KERNEL_SIZE'], padding=config['PADDING'], kernel_initializer=config['INITIALIZER'])(x)\n",
    "            shortcut = BatchNormalization()(shortcut)\n",
    "            out = Add()([shortcut, out])\n",
    "        return out\n",
    "    \n",
    "    def _downsample_block(self, x, n_filters, n_convs, residual=False):\n",
    "        f = self._conv_block(x, n_filters, n_convs, residual)\n",
    "        p = MaxPooling2D(2)(f)\n",
    "        p = Dropout(config['DROPOUT'])(p)\n",
    "        return f, p\n",
    "    \n",
    "    def _upsample_block(self, x, conv_features, n_filters, n_convs, residual=False):\n",
    "        x = Conv2DTranspose(n_filters, 2, 2, padding=config['PADDING'])(x)\n",
    "        x = concatenate([x, *conv_features])\n",
    "        x = Dropout(config['DROPOUT'])(x)\n",
    "        x = self._conv_block(x, n_filters, n_convs, residual)\n",
    "        return x\n",
    "\n",
    "    \n",
    "    def create_model(self):\n",
    "        inputs = Input(shape=(config['IMAGE_SIZE'], config['IMAGE_SIZE'], config['CHANNELS']))\n",
    "        # encoder\n",
    "        # 1 - downsample\n",
    "        conv1_1, pool1 = self._downsample_block(inputs, config['FILTERS'], 2, False)\n",
    "        # 2 - downsample\n",
    "        conv2_1, pool2 = self._downsample_block(pool1, config['FILTERS'] * 2, 2, False)\n",
    "        \n",
    "        conv1_2 = self._upsample_block(conv2_1, [conv1_1], config['FILTERS'], 2, False)\n",
    "        \n",
    "        \n",
    "        # 3 - downsample\n",
    "        conv3_1, pool3 = self._downsample_block(pool2, config['FILTERS'] * 4, 2, False)\n",
    "        \n",
    "        conv2_2 = self._upsample_block(conv3_1, [conv2_1], config['FILTERS'] * 2, 2, False)\n",
    "        conv1_3 = self._upsample_block(conv2_2, [conv1_1, conv1_2], config['FILTERS'], 2, False)\n",
    "        \n",
    "        # 4 - downsample\n",
    "        conv4_1, pool4 = self._downsample_block(pool3, config['FILTERS'] * 8, 2, False)\n",
    "        \n",
    "        conv3_2 = self._upsample_block(conv4_1, [conv3_1], config['FILTERS'] * 4, 2, False)\n",
    "        conv2_3 = self._upsample_block(conv3_2, [conv2_1, conv2_2], config['FILTERS'] * 2, 2, False)\n",
    "        conv1_4 = self._upsample_block(conv2_3, [conv1_1, conv1_2, conv1_3], config['FILTERS'], 2, False)\n",
    "        \n",
    "        # 5 - bottleneck\n",
    "        conv5_1 = self._conv_block(pool4, config['FILTERS'] * 16, 2, False)\n",
    "        \n",
    "        conv4_2 = self._upsample_block(conv5_1, [conv4_1], config['FILTERS'] * 8, 2, False)\n",
    "        conv3_3 = self._upsample_block(conv4_2, [conv3_1, conv3_2], config['FILTERS'] * 4, 2, False)\n",
    "        conv2_4 = self._upsample_block(conv3_3, [conv2_1, conv2_2, conv2_3], config['FILTERS'] * 2, 2, False)\n",
    "        conv1_5 = self._upsample_block(conv2_4, [conv1_1, conv1_2, conv1_3, conv1_4], config['FILTERS'], 2, False)\n",
    "            \n",
    "        # outputs\n",
    "        outputs = Conv2D(1, 1, padding=config['PADDING'], activation = \"sigmoid\")(conv1_5)\n",
    "\n",
    "        unet_model = Model(inputs, outputs, name=\"NestedU-Net\")\n",
    "        \n",
    "        return unet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecfcd66-8cb6-47f9-956e-caa386474057",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NestedUnet().create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4be5ff-a39a-42f5-b829-453327c9f807",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(tf.keras.utils.Sequence):\n",
    "    def __init__(self, batch_size, img_size, directory, img_json, augmentations):\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.img_json = img_json\n",
    "        self.img_paths =  []\n",
    "        self.directory = directory\n",
    "        self.augmentations = [{\"type\": \"normal\"}] + augmentations\n",
    "        \n",
    "        for aug_idx, augmentation in enumerate(self.augmentations):\n",
    "            for index, image in enumerate(self.img_json['images']):\n",
    "                for index_patch in range(len(image['patches'])):\n",
    "                    coors = image['patches'][index_patch] + [index, augmentation] \n",
    "                    self.img_paths.append(coors)\n",
    "                    \n",
    "        self.on_epoch_end()\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.img_paths) // self.batch_size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        i = idx * self.batch_size\n",
    "        indexes = self.indexes[i : i + self.batch_size]\n",
    "        batch_imgs = [self.img_paths[k] for k in indexes]\n",
    "        \n",
    "        x = np.zeros((self.batch_size,) + self.img_size + (config['CHANNELS'],), dtype=\"float32\")\n",
    "        y = np.zeros((self.batch_size,) + self.img_size + (1,), dtype=\"float32\")\n",
    "        for index, batch in enumerate(batch_imgs):\n",
    "            y_idx, x_idx, file_idx, augmentation = batch\n",
    "            file_name = self.img_json['images'][file_idx]['name'].replace('.tif', '').replace('.png','')\n",
    "            img = load_img(os.path.join(self.directory, file_name + '_' + str(y_idx) +'_' + str(x_idx) + '.tif'), color_mode='rgb')\n",
    "            img = np.array(img) / 255\n",
    "            \n",
    "            mask_name = self.img_json['images'][file_idx]['name']\n",
    "            full_mask = load_img(os.path.join(self.directory.replace('/normalized','/labels'), mask_name.replace('.tif','.png')), color_mode='grayscale')\n",
    "            (left, upper) = (x_idx * config['IMAGE_SIZE'], y_idx * config['IMAGE_SIZE'])\n",
    "            mask = full_mask.crop((left, upper, left + config['IMAGE_SIZE'], upper + config['IMAGE_SIZE']))\n",
    "            mask = np.expand_dims(mask, 2)\n",
    "            mask = (np.array(mask) > 128).astype('float32')\n",
    "            \n",
    "            if augmentation['type'] == 'normal':\n",
    "                x[index] = img\n",
    "                y[index] = mask\n",
    "            elif augmentation['type'] == 'rotation':\n",
    "                x[index] = RandomRotation(factor=augmentation['factor'], interpolation='nearest')(img)\n",
    "                y[index] = RandomRotation(factor=augmentation['factor'], interpolation='nearest')(mask)\n",
    "            elif augmentation['type'] == 'flip':\n",
    "                x[index] = RandomFlip(mode=augmentation['mode'])(img)\n",
    "                y[index] = RandomFlip(mode=augmentation['mode'])(mask)\n",
    "            elif augmentation['type'] == 'zoom':\n",
    "                x[index] = RandomZoom(height_factor=augmentation['height_factor'], width_factor=augmentation['width_factor'], interpolation='nearest')(img)\n",
    "                y[index] = RandomZoom(height_factor=augmentation['height_factor'], width_factor=augmentation['width_factor'], interpolation='nearest')(mask)\n",
    "            elif augmentation['type'] == 'contrast':\n",
    "                x[index] = RandomContrast(factor=augmentation['factor'])(img)\n",
    "                y[index] = RandomContrast(factor=augmentation['factor'])(mask)\n",
    "\n",
    "        return x, y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.img_paths))\n",
    "        np.random.shuffle(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3135fc2-dfe4-4098-a016-a6e7f228dfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diceCoef(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n",
    "    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n",
    "    return K.mean( (2. * intersection + smooth) / (union + smooth), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc245116-41c4-4027-8fbf-1fe74ba38153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diceCoefLoss(y_true, y_pred):\n",
    "    return (1-diceCoef(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6983d427-5fda-493d-a999-31260b30c0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=config['LEARNING_RATE']),\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                  #loss=diceCoefLoss,\n",
    "                  metrics=['Precision', 'Recall', tf.keras.metrics.BinaryIoU(), tf.keras.metrics.MeanIoU(num_classes=2), diceCoef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da039724-cb2a-43c4-87e3-bbe1ffcdd6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('images-train.json') as json_file:\n",
    "    train_json = json.load(json_file)\n",
    "    \n",
    "files = shuffle(train_json['images'], random_state= 42)\n",
    "train_filenames = files[:27]\n",
    "valid_filenames = files[27:]\n",
    "\n",
    "train_json = {\n",
    "    \"images\": train_filenames,\n",
    "    \"patch_size\": train_json['patch_size']\n",
    "}\n",
    "\n",
    "valid_json = {\n",
    "    \"images\": valid_filenames,\n",
    "    \"patch_size\": train_json['patch_size']\n",
    "}\n",
    "\n",
    "with open('images-test.json') as json_file:\n",
    "    test_json = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd80745-8877-4edb-bb54-54de70fed4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 0\n",
    "for image in train_json['images']:\n",
    "    size += len(image['patches'])\n",
    "\n",
    "train_size = size * (len(config['AUGMENTATIONS']) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b31c980-318a-4c52-9688-0a2eab4c9d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(batch_size=config['BATCH_SIZE'], img_size=(config['IMAGE_SIZE'], config['IMAGE_SIZE']), directory='data\\\\train\\\\patches', img_json=train_json, augmentations=config['AUGMENTATIONS'])\n",
    "valid_dataset = Dataset(batch_size=config['BATCH_SIZE'], img_size=(config['IMAGE_SIZE'], config['IMAGE_SIZE']), directory='data\\\\train\\\\patches', img_json=valid_json, augmentations=[])\n",
    "test_dataset = Dataset(batch_size=config['BATCH_SIZE'], img_size=(config['IMAGE_SIZE'], config['IMAGE_SIZE']), directory='data\\\\test\\\\patches', img_json=valid_json, augmentations=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca482815-c3d6-45ea-9119-ea7ba4c97c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    print(\"Name:\", gpu.name, \"  Type:\", gpu.device_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f6e21a-653a-492d-9b14-f3c239243153",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.display(height=720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2b6e5a-8e78-4cec-b4ba-d4ecb78a3dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_save = ModelCheckpoint('.model.hdf5', save_best_only=True, monitor='val_loss', mode='min', save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf7edb8-c5c7-4622-a3d4-9818bb8bf3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset, epochs=config['EPOCHS'], validation_data=valid_dataset, steps_per_epoch = int(train_size // config['BATCH_SIZE']), callbacks=[mcp_save, WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533ab8aa-0d90-47c8-9839-f3c5d6c6ee4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b826238-00e8-4ecb-91dc-69b449e2fc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_sample(display_list):\n",
    "    \"\"\"Show side-by-side an input image,\n",
    "    the ground truth and the prediction.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(18, 18))\n",
    "\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3cc369-cefa-4c3c-aae5-be0c1f9a39fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    index_batch=i\n",
    "    pred_mask = model.predict(train_dataset[index_batch][0])\n",
    "    for j in range(4):\n",
    "        index_img=j\n",
    "        display_sample([train_dataset[index_batch][0][index_img], train_dataset[index_batch][1][index_img], (np.array(pred_mask[index_img]) > config['THRESHOLD']).astype('float32')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff74ce06-e34c-47be-9680-3aa818696238",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(test_dataset, batch_size=config['BATCH_SIZE'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
