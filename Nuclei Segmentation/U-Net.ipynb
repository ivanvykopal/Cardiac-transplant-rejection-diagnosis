{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1618877-631e-407d-86a1-88938c773d97",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Trénovanie U-Net modelu\n",
    "\n",
    "**Autor: Bc. Ivan Vykopal**\n",
    "\n",
    "Notebook určený pre tréning U-Net modelu pre segmentáciu jadier v Lizard datasete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aff026f-2fa5-4479-83b4-8b8975f2bff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, BatchNormalization\n",
    "from tensorflow.keras.layers import MaxPooling2D, ReLU, LeakyReLU, Activation, RandomRotation, RandomFlip, RandomZoom, RandomContrast\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Add\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.image import resize\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "import tensorflow.keras.backend as K\n",
    "import cv2 as cv\n",
    "import json\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad89277c-bfc4-4363-b06e-7ba7798f6f4d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b0de02-db0c-4e5d-bb92-f911613b1e10",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "run = wandb.init(project=\"DP U-Net Lizard\", entity=\"ivanvykopal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477766ad-7d0a-4406-b000-fa5d1f50a6c9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'IMAGE_SIZE': 512,\n",
    "    'CHANNELS': 3,\n",
    "    'BATCH_SIZE': 4,\n",
    "    'EPOCHS': 100,\n",
    "    'PADDING': 'same',\n",
    "    'DTYPE': 'float32',\n",
    "    'FILTERS': 16,\n",
    "    'INITIALIZER': 'he_normal',\n",
    "    'KERNEL_SIZE': (3, 3),\n",
    "    'LEARNING_RATE': 0.001,\n",
    "    'DROPOUT': 0,\n",
    "    'THRESHOLD': 0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779b15d5-0582-4b7a-ba91-19d86cd4dc01",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wandb.config.update(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7059280c-8fd5-420f-a5bd-7de9183bb5cf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Unet():\n",
    "    def __init__(self):\n",
    "        super()\n",
    "     \n",
    "    def _conv_block(self, x, n_filters, n_convs, residual=False):\n",
    "        out = tf.identity(x)\n",
    "        for i in range(n_convs):\n",
    "            out = Conv2D(n_filters, kernel_size=config['KERNEL_SIZE'], padding=config['PADDING'], kernel_initializer=config['INITIALIZER'])(out)\n",
    "            out = BatchNormalization()(out)\n",
    "            out = Activation('relu')(out)\n",
    "            \n",
    "        if residual:\n",
    "            shortcut = Conv2D(n_filters, kernel_size=config['KERNEL_SIZE'], padding=config['PADDING'], kernel_initializer=config['INITIALIZER'])(x)\n",
    "            shortcut = BatchNormalization()(shortcut)\n",
    "            out = Add()([shortcut, out])\n",
    "        return out\n",
    "    \n",
    "    def _downsample_block(self, x, n_filters, n_convs, residual=False):\n",
    "        f = self._conv_block(x, n_filters, n_convs, residual)\n",
    "        p = MaxPooling2D(2)(f)\n",
    "        p = Dropout(config['DROPOUT'])(p)\n",
    "        return f, p\n",
    "    \n",
    "    def _upsample_block(self, x, conv_features, n_filters, n_convs, residual=False):\n",
    "        x = Conv2DTranspose(n_filters, 2, 2, padding=config['PADDING'])(x)\n",
    "        x = concatenate([x, *conv_features])\n",
    "        x = Dropout(config['DROPOUT'])(x)\n",
    "        x = self._conv_block(x, n_filters, n_convs, residual)\n",
    "        return x\n",
    "\n",
    "    \n",
    "    def create_model(self):\n",
    "        inputs = Input(shape=(config['IMAGE_SIZE'], config['IMAGE_SIZE'], config['CHANNELS']))\n",
    "        # encoder\n",
    "        # 1 - downsample\n",
    "        conv1_1, pool1 = self._downsample_block(inputs, config['FILTERS'], 2, False)\n",
    "        # 2 - downsample\n",
    "        conv2_1, pool2 = self._downsample_block(pool1, config['FILTERS'] * 2, 2, False)\n",
    "        \n",
    "        conv1_2 = self._upsample_block(conv2_1, [conv1_1], config['FILTERS'], 2, False)\n",
    "        \n",
    "        \n",
    "        # 3 - downsample\n",
    "        conv3_1, pool3 = self._downsample_block(pool2, config['FILTERS'] * 4, 2, False)\n",
    "        \n",
    "        conv2_2 = self._upsample_block(conv3_1, [conv2_1], config['FILTERS'] * 2, 2, False)\n",
    "        conv1_3 = self._upsample_block(conv2_2, [conv1_1, conv1_2], config['FILTERS'], 2, False)\n",
    "        \n",
    "        # 4 - downsample\n",
    "        conv4_1, pool4 = self._downsample_block(pool3, config['FILTERS'] * 8, 2, False)\n",
    "        \n",
    "        conv3_2 = self._upsample_block(conv4_1, [conv3_1], config['FILTERS'] * 4, 2, False)\n",
    "        conv2_3 = self._upsample_block(conv3_2, [conv2_1, conv2_2], config['FILTERS'] * 2, 2, False)\n",
    "        conv1_4 = self._upsample_block(conv2_3, [conv1_1, conv1_2, conv1_3], config['FILTERS'], 2, False)\n",
    "        \n",
    "        # 5 - bottleneck\n",
    "        conv5_1 = self._conv_block(pool4, config['FILTERS'] * 16, 2, False)\n",
    "        \n",
    "        conv4_2 = self._upsample_block(conv5_1, [conv4_1], config['FILTERS'] * 8, 2, False)\n",
    "        conv3_3 = self._upsample_block(conv4_2, [conv3_1, conv3_2], config['FILTERS'] * 4, 2, False)\n",
    "        conv2_4 = self._upsample_block(conv3_3, [conv2_1, conv2_2, conv2_3], config['FILTERS'] * 2, 2, False)\n",
    "        conv1_5 = self._upsample_block(conv2_4, [conv1_1, conv1_2, conv1_3, conv1_4], config['FILTERS'], 2, False)\n",
    "            \n",
    "        # outputs\n",
    "        outputs = Conv2D(1, 1, padding=config['PADDING'], activation = \"sigmoid\")(conv1_5)\n",
    "\n",
    "        unet_model = Model(inputs, outputs, name=\"U-Net\")\n",
    "        \n",
    "        return unet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b4f255-77ce-46d0-94dd-2db88a36bee1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def diceCoef(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n",
    "    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n",
    "    return K.mean( (2. * intersection + smooth) / (union + smooth), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bdd1da-b693-4576-8b5d-40b599665689",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def diceCoefLoss(y_true, y_pred):\n",
    "    return (1-diceCoef(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f6de09-fae6-43d1-ae45-1de8a6a4e3f4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = Unet().create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec64d2ea-b595-4c8c-aa17-cffa9faf5cd3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c9552d-2b38-4288-b42f-c6856d2e6017",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=config['LEARNING_RATE']),\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                  #loss=diceCoefLoss,\n",
    "                  metrics=['Precision', 'Recall', tf.keras.metrics.BinaryIoU(), tf.keras.metrics.MeanIoU(num_classes=2), diceCoef])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bf0f70-5043-4e18-b5e0-9012593b17a5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "{\n",
    "    \"type\": \"flip\",\n",
    "    \"mode\": \"horizontal_and_vertical\" / \"horizontal\" / \"vertical\"\n",
    "},\n",
    "{\n",
    "    \"type\": \"rotation\",\n",
    "    \"factor\": float\n",
    "},\n",
    "{\n",
    "    \"type\": \"normal\"\n",
    "},\n",
    "{\n",
    "    \"type\": \"zoom\",\n",
    "    \"height_factor\": float,\n",
    "    \"width_factor\": float\n",
    "},\n",
    "{\n",
    "    \"type\": \"contrast\",\n",
    "    \"factor\": float\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba27ddb-d2cf-4067-893e-83e6441e6f61",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, batch_size, img_size, directory, img_json, augmentations):\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.img_json = img_json\n",
    "        self.img_paths =  []\n",
    "        self.directory = directory\n",
    "        self.augmentations = [{\"type\": \"normal\"}] + augmentations\n",
    "        \n",
    "        for aug_idx, augmentation in enumerate(self.augmentations):\n",
    "            for index, image in enumerate(self.img_json['images']):\n",
    "                for index_patch in range(len(image['patches'])):\n",
    "                    coors = image['patches'][index_patch] + [(aug_idx * len(self.img_json['images'])) + index, augmentation] \n",
    "                    self.img_paths.append(coors)\n",
    "        print(len(self.img_paths))\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.img_paths) // self.batch_size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        i = idx * self.batch_size\n",
    "        batch_imgs = self.img_paths[i : i + self.batch_size]\n",
    "        \n",
    "        x = np.zeros((self.batch_size,) + self.img_size + (config['CHANNELS'],), dtype=\"float32\")\n",
    "        y = np.zeros((self.batch_size,) + self.img_size + (1,), dtype=\"float32\")\n",
    "        for index, batch in enumerate(batch_imgs):\n",
    "            y_idx, x_idx, file_idx, augmentation = batch\n",
    "            file_idx = file_idx % len(self.img_json['images'])\n",
    "            file_name = self.img_json['images'][file_idx]['name'].replace('.tif', '')\n",
    "            img = load_img(os.path.join(self.directory, file_name + '_' + str(y_idx) +'_' + str(x_idx) + '.tif'), color_mode='rgb')\n",
    "            #x[index] = np.array(img) / 255\n",
    "            img = np.array(img) / 255\n",
    "            \n",
    "            mask_name = self.img_json['images'][file_idx]['name']\n",
    "            full_mask = load_img(os.path.join(self.directory.replace('patches','masks'), mask_name.replace('.tif','.png')), color_mode='grayscale')\n",
    "            #mask = full_mask[y_idx * config['IMAGE_SIZE']:(y_idx + 1) * config['IMAGE_SIZE'], x_idx * config['IMAGE_SIZE']:(x_idx + 1) * config['IMAGE_SIZE']]\n",
    "            (left, upper) = (x_idx * config['IMAGE_SIZE'], y_idx * config['IMAGE_SIZE'])\n",
    "            mask = full_mask.crop((left, upper, left + config['IMAGE_SIZE'], upper + config['IMAGE_SIZE']))\n",
    "            mask = np.expand_dims(mask, 2)\n",
    "            mask = (np.array(mask) > 128).astype('float32')\n",
    "            #y[index] = mask\n",
    "            \n",
    "            if augmentation['type'] == 'normal':\n",
    "                x[index] = img\n",
    "                y[index] = mask\n",
    "            elif augmentation['type'] == 'rotation':\n",
    "                x[index] = RandomRotation(factor=augmentation['factor'], interpolation='nearest')(img)\n",
    "                y[index] = RandomRotation(factor=augmentation['factor'], interpolation='nearest')(mask)\n",
    "            elif augmentation['type'] == 'flip':\n",
    "                x[index] = RandomFlip(mode=augmentation['mode'])(img)\n",
    "                y[index] = RandomFlip(mode=augmentation['mode'])(mask)\n",
    "            elif augmentation['type'] == 'zoom':\n",
    "                x[index] = RandomZoom(height_factor=augmentation['height_factor'], width_factor=augmentation['width_factor'], interpolation='nearest')(img)\n",
    "                y[index] = RandomZoom(height_factor=augmentation['height_factor'], width_factor=augmentation['width_factor'], interpolation='nearest')(mask)\n",
    "            elif augmentation['type'] == 'contrast':\n",
    "                x[index] = RandomContrast(factor=augmentation['factor'])(img)\n",
    "                y[index] = RandomContrast(factor=augmentation['factor'])(mask)\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a47bff-d27f-4fd9-bf25-8051de254382",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('images-train.json') as json_file:\n",
    "    train_json = json.load(json_file)\n",
    "    \n",
    "files = shuffle(train_json['images'], random_state= 42)\n",
    "train_filenames = files[:27]\n",
    "valid_filenames = files[27:]\n",
    "\n",
    "train_json = {\n",
    "    \"images\": train_filenames,\n",
    "    \"patch_size\": train_json['patch_size']\n",
    "}\n",
    "\n",
    "valid_json = {\n",
    "    \"images\": valid_filenames,\n",
    "    \"patch_size\": train_json['patch_size']\n",
    "}\n",
    "\n",
    "with open('images-test.json') as json_file:\n",
    "    test_json = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f37349-f381-4a46-b1e2-b774768dec6b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "augmentations = [\n",
    "    {\n",
    "        \"type\": \"flip\",\n",
    "        \"mode\": \"horizontal_and_vertical\"\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"flip\",\n",
    "        \"mode\": \"vertical\"\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"flip\",\n",
    "        \"mode\": \"horizontal\"\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"zoom\",\n",
    "        \"height_factor\": 0.5,\n",
    "        \"width_factor\": 0.5\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"zoom\",\n",
    "        \"height_factor\": 0.2,\n",
    "        \"width_factor\": 0.2\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"contrast\",\n",
    "        \"factor\": 0.2\n",
    "    }, \n",
    "    {\n",
    "        \"type\": \"contrast\",\n",
    "        \"factor\": 0.5\n",
    "    }, \n",
    "    {\n",
    "        \"type\": \"contrast\",\n",
    "        \"factor\": 0.7\n",
    "    }\n",
    "]\n",
    "\n",
    "size = 0\n",
    "for image in train_json['images']:\n",
    "    size += len(image['patches'])\n",
    "\n",
    "train_size = size * (len(augmentations) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4776b15d-6cf2-4147-81cd-61c224c2b134",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset(batch_size=config['BATCH_SIZE'], img_size=(config['IMAGE_SIZE'], config['IMAGE_SIZE']), directory='data\\\\train\\\\patches', img_json=train_json, augmentations=augmentations)\n",
    "valid_dataset = Dataset(batch_size=config['BATCH_SIZE'], img_size=(config['IMAGE_SIZE'], config['IMAGE_SIZE']), directory='data\\\\train\\\\patches', img_json=valid_json, augmentations=[])\n",
    "test_dataset = Dataset(batch_size=config['BATCH_SIZE'], img_size=(config['IMAGE_SIZE'], config['IMAGE_SIZE']), directory='data\\\\test\\\\patches', img_json=test_json, augmentations=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a74b45-f8e6-4e8a-a9ae-f4d3f1fd2079",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    print(\"Name:\", gpu.name, \"  Type:\", gpu.device_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8842ab-64f3-41d9-b0bc-fbbfc20f4611",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "run.display(height=720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55df68af-b2b9-4eb8-a3ad-5cdbfffcb4ad",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset, epochs=config['EPOCHS'], validation_data=valid_dataset, steps_per_epoch = int(train_size // config['BATCH_SIZE']), callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a77dc75-ac96-4e67-b195-2164aede2a04",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d12d693-8210-400a-bd3a-80f25dc5fcdc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def display_sample(display_list):\n",
    "    \"\"\"Show side-by-side an input image,\n",
    "    the ground truth and the prediction.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(18, 18))\n",
    "\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ac432e-9207-47ad-9c71-3f10f72e0cc2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    index_batch=i\n",
    "    pred_mask = model.predict(train_dataset[index_batch][0])\n",
    "    for j in range(4):\n",
    "        index_img=j\n",
    "        display_sample([train_dataset[index_batch][0][index_img], train_dataset[index_batch][1][index_img], (np.array(pred_mask[index_img]) > config['THRESHOLD']).astype('float32')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d189297e-dd4e-4527-b65c-623a704ceaf9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results = model.evaluate(test_dataset, batch_size=config['BATCH_SIZE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dafce0-85f4-46da-9597-8c9cdf17eecb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(test_json['images']) // config['BATCH_SIZE']):\n",
    "    index_batch=i\n",
    "    pred_mask = model.predict(test_dataset[index_batch][0])\n",
    "    for j in range(config['BATCH_SIZE']):\n",
    "        index_img=j\n",
    "        display_sample([test_dataset[index_batch][0][index_img], test_dataset[index_batch][1][index_img], (np.array(pred_mask[index_img]) > config['THRESHOLD']).astype('float32')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb322623-7703-4cc0-9b51-7f2e03ac5b4f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def save_predictions(dataset, files):\n",
    "    index = 0\n",
    "    for i in range(len(files) // config['BATCH_SIZE']):\n",
    "        for j in range(config['BATCH_SIZE']):\n",
    "            pred_mask = model.predict(dataset[i][0])\n",
    "            image1 = cv.copyMakeBorder(dataset[i][0][j], 5, 5, 5, 5, cv.BORDER_CONSTANT, value=[255, 255, 255])\n",
    "            image2 = cv.copyMakeBorder(dataset[i][1][j], 5, 5, 5, 5, cv.BORDER_CONSTANT, value=[255, 255, 255])\n",
    "            image3 = cv.copyMakeBorder((np.array(pred_mask[j]) > 0.25).astype('float32').squeeze(), 5, 5, 5, 5, cv.BORDER_CONSTANT, value=[255, 255, 255])\n",
    "            im_h = cv.hconcat([image1, image2, image3])\n",
    "            im_h = np.expand_dims(im_h * 255, 2)\n",
    "            cv.imwrite('predicted masks/' + str(index) + '.png', im_h)\n",
    "            index += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
